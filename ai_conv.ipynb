{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "# Import dotenv package for setting environment variables \n",
    "# Import os package\n",
    "import os\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.prompts.prompt import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set environment variables from the .env in the local environment\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the OpenAI API key\n",
    "OPENAI_API_KEY = os.environ.get(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the ChatOpenAI object for interacting with the OpenAI API\n",
    "llm = ChatOpenAI(openai_api_key=OPENAI_API_KEY)\n",
    "\n",
    "# Initialize the WebBaseLoader to load documents from a URL\n",
    "loader = WebBaseLoader(\"https://docs.smith.langchain.com/overview\")\n",
    "docs = loader.load()  # Load documents from the specified URL\n",
    "\n",
    "# Initialize the OpenAIEmbeddings for generating embeddings\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "# Initialize the RecursiveCharacterTextSplitter to split documents into segments\n",
    "text_splitter = RecursiveCharacterTextSplitter()\n",
    "documents = text_splitter.split_documents(docs)  # Split documents into segments\n",
    "vector = FAISS.from_documents(documents, embeddings)  # Generate vector representations of documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a template for generating prompts\n",
    "template = (\n",
    "    \"Combine the chat history and follow up question into \"\n",
    "    \"a standalone question. Chat History: {chat_history}\"\n",
    "    \"Follow up question: {question}\"\n",
    ")\n",
    "\n",
    "# Create a PromptTemplate instance from the template\n",
    "prompt = PromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Hello, I am Chris\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Hello Chris! It's nice to meet you. I'm a language model AI trained by OpenAI, designed to help answer questions and engage in conversation. How can I assist you today?\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the ConversationChain for managing conversation flow\n",
    "conversation = ConversationChain(\n",
    "    llm=llm,  # OpenAI language model\n",
    "    verbose=True,  # Enable verbose mode for logging\n",
    "    memory=ConversationBufferMemory()  # Use ConversationBufferMemory for storing conversation history\n",
    ")\n",
    "\n",
    "# Perform prediction based on the input prompt\n",
    "conversation.predict(input=\"Hello, I am Chris\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
